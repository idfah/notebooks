{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring PyTorch Lightning for Classifying MNIST Handwritten Digits\n",
    "\n",
    "---\n",
    "\n",
    "__Elliott Forney - 2021__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = np.stack([train_data[i][0] for i in range(16)])\n",
    "#montage = ski.util.montage(images)\n",
    "#plt.imshow(montage, cmap=plt.cm.gray_r);\n",
    "#plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data/torchvision/'\n",
    "\n",
    "class MNISTData(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=1024, num_workers=10):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        tv.datasets.MNIST(datadir, download=True)\n",
    "        tv.datasets.MNIST(datadir, download=True)\n",
    "    \n",
    "    def setup(self, stage=None):        \n",
    "        all_train_data = tv.datasets.MNIST(\n",
    "            datadir,\n",
    "            transform=tv.transforms.ToTensor(),\n",
    "            train=True)\n",
    "        self.train_data, self.valid_data = th.utils.data.random_split(\n",
    "            all_train_data, (50_000, 10_000))\n",
    "        \n",
    "        self.test_data = tv.datasets.MNIST(\n",
    "            datadir,\n",
    "            transform=tv.transforms.ToTensor(),\n",
    "            train=False)\n",
    "        \n",
    "    def plot_montage(self, n=16):\n",
    "        images = np.stack([self.valid_data[i][0] for i in range(n)])\n",
    "        montage = ski.util.montage(images)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(montage, cmap=plt.cm.gray_r)\n",
    "        ax.axis('off')\n",
    "        return {\n",
    "            'fig': fig,\n",
    "            'ax': ax,\n",
    "        }\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return th.utils.data.DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "            shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return th.utils.data.DataLoader(\n",
    "            self.valid_data,\n",
    "            batch_size=self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return th.utils.data.DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=False,\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = MNISTData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNISTData' object has no attribute 'train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d668bf6eac7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-a580fcf774c3>\u001b[0m in \u001b[0;36mtrain_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         return th.utils.data.DataLoader(\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNISTData' object has no attribute 'train_data'"
     ]
    }
   ],
   "source": [
    "mnist_data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(pl.LightningModule):\n",
    "    def __init__(self, height=28, width=28, nclass=10, nhiddens=(128, 64, 32)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.height, self.width = height, width\n",
    "        self.nclass = nclass\n",
    "        self.nhiddens = nhiddens\n",
    "        \n",
    "        hiddens = []\n",
    "        layer_in, layer_out = None, self.height * self.width\n",
    "        for nhidden in self.nhiddens:\n",
    "            layer_in, layer_out = layer_out, nhidden\n",
    "            hiddens.extend([\n",
    "                th.nn.BatchNorm1d(layer_in),\n",
    "                th.nn.Linear(layer_in, layer_out),\n",
    "                th.nn.ReLU(),\n",
    "            ])\n",
    "        self.hiddens = th.nn.Sequential(*hiddens)\n",
    "        \n",
    "        layer_in, layer_out = layer_out, nclass\n",
    "        self.visible = th.nn.Linear(layer_in, layer_out)\n",
    "        \n",
    "        self.train_accuracy = pl.metrics.Accuracy()\n",
    "        self.valid_accuracy = pl.metrics.Accuracy()\n",
    "        self.test_accuracy = pl.metrics.Accuracy()\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        assert imgs.ndim == 4\n",
    "        assert imgs.shape[1] == 1\n",
    "        assert imgs.shape[2] == self.height\n",
    "        assert imgs.shape[3] == self.width\n",
    "        batch_size = imgs.shape[0]\n",
    "        \n",
    "        flat_imgs = imgs.view((batch_size, -1))\n",
    "        hidden_out = self.hiddens(flat_imgs)\n",
    "        assert hidden_out.shape == (batch_size, self.nhiddens[-1])\n",
    "        \n",
    "        visible_out = self.visible(hidden_out)\n",
    "        assert visible_out.shape == (batch_size, self.nclass)\n",
    "        \n",
    "        return visible_out\n",
    "    \n",
    "    def predict(self, batch, batch_idx=None, dataloader_idx=None):\n",
    "        imgs, labels = batch\n",
    "        #return th.softmax(self(imgs), dim=1)\n",
    "        return self(imgs).argmax(1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return th.optim.Adam(self.parameters(), lr=0.0015)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = th.nn.functional.cross_entropy(logits, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        probs = th.softmax(logits, dim=1)\n",
    "        train_acc_step = self.train_accuracy(probs, labels)\n",
    "        self.log('train_acc_step', train_acc_step, on_step=True, on_epoch=False)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.log('train_acc_epoch', self.train_accuracy.compute(), prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = th.nn.functional.cross_entropy(logits, labels)\n",
    "        self.log('valid_loss_epoch', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        probs = th.softmax(logits, dim=1)\n",
    "        valid_acc_step = self.valid_accuracy(probs, labels)\n",
    "        self.log('valid_acc_step', valid_acc_step, on_step=False, on_epoch=False)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = th.nn.functional.cross_entropy(logits, labels)\n",
    "        self.log('test_loss', loss)\n",
    "        \n",
    "        probs = th.softmax(logits, dim=1)\n",
    "        test_acc_step = self.test_accuracy(probs, labels)\n",
    "        self.log('test_acc', test_acc_step)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log('valid_acc_epoch', self.valid_accuracy.compute(), prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (hiddens): Sequential(\n",
       "    (0): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (8): ReLU()\n",
       "  )\n",
       "  (visible): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (train_accuracy): Accuracy()\n",
       "  (valid_accuracy): Accuracy()\n",
       "  (test_accuracy): Accuracy()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model = DenseNet()\n",
    "dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class ProgressBar(pl.callbacks.progress.ProgressBar):\n",
    "    def init_train_tqdm(self):        \n",
    "        bar = tqdm.notebook.tqdm(\n",
    "            desc='Training',\n",
    "            initial=self.train_batch_idx,\n",
    "            position=(2 * self.process_position),\n",
    "            disable=self.is_disabled,\n",
    "            leave=True,\n",
    "            dynamic_ncols=True,\n",
    "            file=sys.stdout,\n",
    "            smoothing=0)        \n",
    "        return bar\n",
    "    \n",
    "    def init_validation_tqdm(self):\n",
    "        bar = tqdm.notebook.tqdm(\n",
    "            desc='Validating',\n",
    "            position=(2 * self.process_position + 1),\n",
    "            disable=self.is_disabled,\n",
    "            leave=False,\n",
    "            dynamic_ncols=True,\n",
    "            file=sys.stdout\n",
    "        )\n",
    "        return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('./lightning_logs/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring valid_loss_epoch.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    pl.callbacks.early_stopping.EarlyStopping(monitor='valid_loss_epoch', patience=10, verbose=True),\n",
    "    #ProgressBar(),\n",
    "]\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | hiddens        | Sequential | 112 K \n",
      "1 | visible        | Linear     | 330   \n",
      "2 | train_accuracy | Accuracy   | 0     \n",
      "3 | valid_accuracy | Accuracy   | 0     \n",
      "4 | test_accuracy  | Accuracy   | 0     \n",
      "----------------------------------------------\n",
      "113 K     Trainable params\n",
      "0         Non-trainable params\n",
      "113 K     Total params\n",
      "0.452     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b18d71a03549318e0a4a36feb9029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5925a149de13463b859eef081f2ce45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3894eeb1e969424aac77165ea9d3905d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65f7d5cbe924488825997f9619c5a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59be93464bf34a1f87c303d1e7278975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d32978a29f4ec0aad01d6fafcea07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78569e3563614272accbce0ccbc3818c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb135e2b368476a89e2b875c9b65dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8062440e4845debad969e68c26f58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d94ccb1675848bca2e8ff412475db7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7537358867114d37bc44a85dffc35f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c780429adb4849a0129c39cc5474be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.fit(dense_model, mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 118597), started 23:47:43 ago. (Use '!kill 118597' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f024ca8e12748803\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f024ca8e12748803\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0173ebf2d28441f797d61e6c4800b56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9721999764442444, 'test_loss': 0.10368657112121582}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10368657112121582, 'test_acc': 0.9721999764442444}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(dense_model, datamodule=mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea6b1fa39ae4fc2af34e7b59a66c8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 48it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(dense_model, datamodule=mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = mnist_data.test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_image.squeeze(0), cmap=plt.cm.gray);\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = np.stack([train_data[i][0] for i in range(16)])\n",
    "#montage = ski.util.montage(images)\n",
    "#plt.imshow(montage, cmap=plt.cm.gray_r);\n",
    "#plt.axis('off');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
